{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "201202_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOalh/wJAbgKO6LQD9OXgVg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoonYoung-Sohn/practice/blob/master/201202_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Pd-q7Lpzx-"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-2zH6pLqylD",
        "outputId": "54071378-50c7-4984-bf09-30fdde3ec779"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, input_shape=(2,10)))\n",
        "# model.add(SimpleRNN(3, input_length=2, input_dim=10))\n",
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 3)                 42        \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVlbWtx8rCcJ",
        "outputId": "ea3bec8d-cade-4cc1-bded-e7e433254363"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, batch_input_shape=(8,2,10)))\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (8, 3)                    42        \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qciVXy4Nrfkh",
        "outputId": "cceccd91-116e-4874-acfe-117217581482"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, batch_input_shape=(8,2,10), return_sequences=True))\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_2 (SimpleRNN)     (8, 2, 3)                 42        \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fEzPNTksN1J"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "timesteps = 10 # 시점의 수. NLP에서는 보통 문장의 길이가 된다.\n",
        "input_dim = 4 # 입력의 차원. NLP에서는 보통 단어 벡터의 차원이 된다.\n",
        "hidden_size = 8 # 은닉 상태의 크기. 메모리 셀의 용량이다.\n",
        "\n",
        "inputs = np.random.random((timesteps, input_dim)) # 입력에 해당되는 2D 텐서\n",
        "\n",
        "hidden_state_t = np.zeros((hidden_size,)) # 초기 은닉 상태는 0(벡터)로 초기화"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0zsADvnsb_O",
        "outputId": "65c9ba6a-d9d0-40b6-d388-c1fb1ce3f5ba"
      },
      "source": [
        "print(hidden_state_t)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GueQjHx4ses0"
      },
      "source": [
        "Wx = np.random.random((hidden_size, input_dim))  # (8, 4)크기의 2D 텐서 생성. 입력에 대한 가중치.\n",
        "Wh = np.random.random((hidden_size, hidden_size)) # (8, 8)크기의 2D 텐서 생성. 은닉 상태에 대한 가중치.\n",
        "b = np.random.random((hidden_size,)) # (8,)크기의 1D 텐서 생성. 이 값은 편향(bias)."
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40UpYlXcs0aq",
        "outputId": "0cdeda9b-b6d3-4049-db28-b0b9ad8810ac"
      },
      "source": [
        "print(np.shape(Wx))\n",
        "print(np.shape(Wh))\n",
        "print(np.shape(b))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 4)\n",
            "(8, 8)\n",
            "(8,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MIHK42Es3C9",
        "outputId": "a02f6204-7a34-4e07-c4bf-c2f5f5c35313"
      },
      "source": [
        "total_hidden_states = []\n",
        "\n",
        "for input_t in inputs: \n",
        "  output_t = np.tanh(np.dot(Wx,input_t) + np.dot(Wh,hidden_state_t) + b) # Wx * Xt + Wh * Ht-1 + b(bias)\n",
        "  total_hidden_states.append(list(output_t)) \n",
        "  print(np.shape(total_hidden_states)) #(timestep, output_dim)\n",
        "  hidden_state_t = output_t\n",
        "\n",
        "total_hidden_states = np.stack(total_hidden_states, axis = 0) \n",
        "\n",
        "print(total_hidden_states) # (timesteps, output_dim)의 크기. "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 8)\n",
            "(2, 8)\n",
            "(3, 8)\n",
            "(4, 8)\n",
            "(5, 8)\n",
            "(6, 8)\n",
            "(7, 8)\n",
            "(8, 8)\n",
            "(9, 8)\n",
            "(10, 8)\n",
            "[[0.94650423 0.9709604  0.93717172 0.8278919  0.81600463 0.54879451\n",
            "  0.96677856 0.89983669]\n",
            " [0.99956463 0.99989191 0.99999306 0.99944268 0.99994495 0.99938579\n",
            "  0.99996848 0.99992677]\n",
            " [0.99976714 0.99988638 0.99999719 0.99974643 0.99997814 0.9997548\n",
            "  0.99997243 0.99995337]\n",
            " [0.99995289 0.99998262 0.99999885 0.99990957 0.99999542 0.99984943\n",
            "  0.99999597 0.99999565]\n",
            " [0.99996867 0.99999259 0.99999966 0.99997438 0.99999851 0.99989408\n",
            "  0.99999924 0.99999886]\n",
            " [0.99994347 0.99998412 0.9999988  0.99985268 0.99999362 0.99984836\n",
            "  0.99999651 0.99999633]\n",
            " [0.99974029 0.99991904 0.99999872 0.99985829 0.99998844 0.99977527\n",
            "  0.99999286 0.99998564]\n",
            " [0.99996598 0.99998627 0.99999918 0.9999536  0.99999548 0.99989449\n",
            "  0.99999377 0.99998833]\n",
            " [0.99996628 0.99998964 0.99999927 0.99994288 0.99999695 0.99987856\n",
            "  0.99999778 0.99999731]\n",
            " [0.99993413 0.99997277 0.99999823 0.99984681 0.99999071 0.9998373\n",
            "  0.99999002 0.99998784]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PpYnp2FwDy0"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3741ikk2bep"
      },
      "source": [
        "text=\"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
        "그의 말이 법이다\\n\n",
        "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKHmm-vC2e6O",
        "outputId": "ed5e74af-e059-440c-c0bb-70b728f5ade5"
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts([text])\n",
        "vocab_size = len(t.word_index) + 1\n",
        "print('단어 집합의 크기 : %d' % vocab_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxQgLYj02mJx",
        "outputId": "b23aa439-9e03-4221-da44-267984672d6e"
      },
      "source": [
        "print(t.word_index)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS1uZ20h2rGe",
        "outputId": "3b4b9fc5-9968-42f4-c374-ed503dc02345"
      },
      "source": [
        "sequences = list()\n",
        "for line in text.split('\\n'): \n",
        "    encoded = t.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "print('학습에 사용할 샘플의 개수: %d' % len(sequences))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습에 사용할 샘플의 개수: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGNmmrwK24MN",
        "outputId": "5fc90448-0091-42f0-b7d4-7173f60a9136"
      },
      "source": [
        "print(sequences)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWo-njAW3Cpl",
        "outputId": "7caa48e3-e788-4709-fda8-3583153080c0"
      },
      "source": [
        "max_len=max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 : {}'.format(max_len))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "샘플의 최대 길이 : 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyCUmSvy3FC1",
        "outputId": "cde459f5-2787-4da6-b907-247a5db9da33"
      },
      "source": [
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "print(sequences)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  2  3]\n",
            " [ 0  0  0  2  3  1]\n",
            " [ 0  0  2  3  1  4]\n",
            " [ 0  2  3  1  4  5]\n",
            " [ 0  0  0  0  6  1]\n",
            " [ 0  0  0  6  1  7]\n",
            " [ 0  0  0  0  8  1]\n",
            " [ 0  0  0  8  1  9]\n",
            " [ 0  0  8  1  9 10]\n",
            " [ 0  8  1  9 10  1]\n",
            " [ 8  1  9 10  1 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVkWuuFJ3Osr"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPh3GFID3QTe",
        "outputId": "21c08caf-2a3a-4513-e1f7-d3fc0197ea43"
      },
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  2]\n",
            " [ 0  0  0  2  3]\n",
            " [ 0  0  2  3  1]\n",
            " [ 0  2  3  1  4]\n",
            " [ 0  0  0  0  6]\n",
            " [ 0  0  0  6  1]\n",
            " [ 0  0  0  0  8]\n",
            " [ 0  0  0  8  1]\n",
            " [ 0  0  8  1  9]\n",
            " [ 0  8  1  9 10]\n",
            " [ 8  1  9 10  1]]\n",
            "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkiDUZWd3UW0"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmF0nCzu3YZN",
        "outputId": "f8d9a48e-4282-4eb4-943d-d7afb064bfb5"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUc-AjuY3ctr"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KA7QPn83fpa",
        "outputId": "b64f3a46-2cca-4e15-dcc8-7168e02f4a92"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=max_len-1)) \n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=200, verbose=2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 - 0s - loss: 2.4892 - accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 2.4734 - accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 2.4579 - accuracy: 0.2727\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 2.4425 - accuracy: 0.4545\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 2.4270 - accuracy: 0.4545\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 2.4115 - accuracy: 0.4545\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 2.3956 - accuracy: 0.4545\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 2.3794 - accuracy: 0.3636\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 2.3626 - accuracy: 0.3636\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 2.3452 - accuracy: 0.3636\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 2.3271 - accuracy: 0.3636\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 2.3082 - accuracy: 0.3636\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 2.2884 - accuracy: 0.3636\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 2.2676 - accuracy: 0.3636\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 2.2460 - accuracy: 0.3636\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 2.2234 - accuracy: 0.3636\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 2.1999 - accuracy: 0.3636\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 2.1756 - accuracy: 0.3636\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 2.1505 - accuracy: 0.3636\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 2.1250 - accuracy: 0.3636\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 2.0992 - accuracy: 0.3636\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 2.0734 - accuracy: 0.3636\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 2.0480 - accuracy: 0.3636\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 2.0234 - accuracy: 0.3636\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 2.0000 - accuracy: 0.3636\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 1.9783 - accuracy: 0.3636\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 1.9585 - accuracy: 0.3636\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 1.9407 - accuracy: 0.3636\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 1.9250 - accuracy: 0.3636\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 1.9108 - accuracy: 0.3636\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 1.8975 - accuracy: 0.3636\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 1.8846 - accuracy: 0.3636\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 1.8712 - accuracy: 0.3636\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 1.8571 - accuracy: 0.3636\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 1.8419 - accuracy: 0.3636\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 1.8256 - accuracy: 0.3636\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 1.8086 - accuracy: 0.3636\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 1.7909 - accuracy: 0.3636\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 1.7729 - accuracy: 0.3636\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 1.7548 - accuracy: 0.3636\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 1.7369 - accuracy: 0.3636\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 1.7191 - accuracy: 0.4545\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 1.7015 - accuracy: 0.4545\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 1.6839 - accuracy: 0.5455\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 1.6662 - accuracy: 0.5455\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 1.6482 - accuracy: 0.5455\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 1.6299 - accuracy: 0.5455\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 1.6110 - accuracy: 0.5455\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 1.5915 - accuracy: 0.5455\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 1.5714 - accuracy: 0.5455\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 1.5507 - accuracy: 0.5455\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 1.5296 - accuracy: 0.5455\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 1.5079 - accuracy: 0.5455\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 1.4859 - accuracy: 0.5455\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 1.4636 - accuracy: 0.5455\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 1.4410 - accuracy: 0.5455\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 1.4182 - accuracy: 0.6364\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 1.3953 - accuracy: 0.6364\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 1.3722 - accuracy: 0.6364\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 1.3490 - accuracy: 0.6364\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 1.3257 - accuracy: 0.6364\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 1.3023 - accuracy: 0.6364\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 1.2788 - accuracy: 0.6364\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 1.2553 - accuracy: 0.6364\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 1.2319 - accuracy: 0.6364\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 1.2085 - accuracy: 0.6364\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 1.1854 - accuracy: 0.6364\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 1.1625 - accuracy: 0.6364\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 1.1400 - accuracy: 0.6364\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 1.1178 - accuracy: 0.6364\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 1.0961 - accuracy: 0.6364\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 1.0749 - accuracy: 0.7273\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 1.0541 - accuracy: 0.7273\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 1.0338 - accuracy: 0.7273\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 1.0141 - accuracy: 0.7273\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 0.9948 - accuracy: 0.7273\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 0.9760 - accuracy: 0.7273\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 0.9577 - accuracy: 0.7273\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 0.9398 - accuracy: 0.7273\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 0.9224 - accuracy: 0.7273\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 0.9055 - accuracy: 0.7273\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 0.8890 - accuracy: 0.7273\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 0.8729 - accuracy: 0.7273\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 0.8573 - accuracy: 0.7273\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 0.8420 - accuracy: 0.7273\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 0.8271 - accuracy: 0.7273\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 0.8125 - accuracy: 0.7273\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 0.7983 - accuracy: 0.7273\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 0.7844 - accuracy: 0.7273\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 0.7708 - accuracy: 0.7273\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 0.7576 - accuracy: 0.7273\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 0.7446 - accuracy: 0.7273\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 0.7319 - accuracy: 0.7273\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 0.7195 - accuracy: 0.7273\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 0.7073 - accuracy: 0.7273\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 0.6955 - accuracy: 0.7273\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 0.6838 - accuracy: 0.8182\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 0.6724 - accuracy: 0.8182\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 0.6613 - accuracy: 0.8182\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 0.6504 - accuracy: 0.8182\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 0.6397 - accuracy: 0.8182\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 0.6292 - accuracy: 0.8182\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 0.6189 - accuracy: 0.8182\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 0.6089 - accuracy: 0.8182\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 0.5990 - accuracy: 0.8182\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 0.5894 - accuracy: 0.8182\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 0.5799 - accuracy: 0.8182\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 0.5706 - accuracy: 0.8182\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 0.5615 - accuracy: 0.8182\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 0.5525 - accuracy: 0.8182\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 0.5438 - accuracy: 0.8182\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 0.5351 - accuracy: 0.8182\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 0.5267 - accuracy: 0.8182\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 0.5184 - accuracy: 0.8182\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 0.5102 - accuracy: 0.8182\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 0.5022 - accuracy: 0.8182\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 0.4943 - accuracy: 0.8182\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 0.4865 - accuracy: 0.8182\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 0.4789 - accuracy: 0.8182\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 0.4714 - accuracy: 0.8182\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 0.4641 - accuracy: 0.8182\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 0.4568 - accuracy: 0.9091\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 0.4497 - accuracy: 0.9091\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 0.4427 - accuracy: 0.9091\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 0.4358 - accuracy: 0.9091\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 0.4290 - accuracy: 0.9091\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 0.4223 - accuracy: 0.9091\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 0.4158 - accuracy: 0.9091\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 0.4093 - accuracy: 0.9091\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.4029 - accuracy: 0.9091\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.3966 - accuracy: 0.9091\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.3904 - accuracy: 0.9091\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.3843 - accuracy: 0.9091\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.3783 - accuracy: 0.9091\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.3723 - accuracy: 0.9091\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.3664 - accuracy: 0.9091\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.3606 - accuracy: 0.9091\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.3549 - accuracy: 0.9091\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.3493 - accuracy: 0.9091\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.3437 - accuracy: 0.9091\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.3382 - accuracy: 0.9091\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.3327 - accuracy: 0.9091\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.3274 - accuracy: 0.9091\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.3220 - accuracy: 0.9091\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.3168 - accuracy: 0.9091\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.3116 - accuracy: 0.9091\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.3065 - accuracy: 0.9091\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.3015 - accuracy: 0.9091\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.2965 - accuracy: 0.9091\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.2915 - accuracy: 0.9091\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.2866 - accuracy: 0.9091\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.2818 - accuracy: 0.9091\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.2771 - accuracy: 0.9091\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.2724 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.2677 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.2632 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.2587 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.2542 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.2498 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.2455 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.2412 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.2370 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.2328 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.2287 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.2247 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.2207 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.2168 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.2129 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.2091 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.2054 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.2017 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.1981 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.1945 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.1911 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.1876 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.1843 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.1810 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.1777 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.1745 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.1714 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.1683 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.1653 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.1624 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.1595 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.1567 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.1539 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.1512 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.1485 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.1459 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.1434 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.1409 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.1384 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.1360 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.1337 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.1314 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.1291 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.1269 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.1248 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.1227 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.1206 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3463d4cb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc1Puqkh4EiJ"
      },
      "source": [
        "def sentence_generation(model, t, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
        "    sentence = ''\n",
        "    for _ in range(n): # n번 반복\n",
        "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\n",
        "        encoded = pad_sequences([encoded], maxlen=5, padding='pre') # 데이터에 대한 패딩\n",
        "        result = model.predict_classes(encoded, verbose=0)\n",
        "    # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
        "        for word, index in t.word_index.items(): \n",
        "            if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "                break # 해당 단어가 예측 단어이므로 break\n",
        "        current_word = current_word + ' '  + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\n",
        "    # for문이므로 이 행동을 다시 반복\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myQAVYrm4rDf",
        "outputId": "381b8e18-4521-44b9-fbdc-7b7769af62a5"
      },
      "source": [
        "print(sentence_generation(model, t, '경마장에', 4))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-120ee9dd07f9>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "경마장에 있는 말이 뛰고 있다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhtfGfo84uum",
        "outputId": "5e749da3-1128-4faf-caa9-e9e90241b0fb"
      },
      "source": [
        "print(sentence_generation(model, t, '그의', 2))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "그의 말이 법이다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqrt8MZq4w9a",
        "outputId": "e731c0f4-c589-4824-d216-bc47dccb81b5"
      },
      "source": [
        "print(sentence_generation(model, t, '가는', 5))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "가는 말이 고와야 오는 말이 곱다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXDchPrt406Z"
      },
      "source": [
        "import pandas as pd\n",
        "from string import punctuation\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "LZjkcBBH6dhb",
        "outputId": "de5466fa-e86b-41ab-ca94-ab852f8b6dc0"
      },
      "source": [
        "from google.colab import files\n",
        "file = files.upload()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1ba654e6-1f70-4d5e-a876-8160b0881224\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1ba654e6-1f70-4d5e-a876-8160b0881224\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ArticlesApril2018.csv to ArticlesApril2018.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szmg7_KY6vmn"
      },
      "source": [
        "df=pd.read_csv('ArticlesApril2018.csv')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "uzOn7sF66xwq",
        "outputId": "866f4012-9e60-4c61-98c6-a95fcaafa331"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articleID</th>\n",
              "      <th>articleWordCount</th>\n",
              "      <th>byline</th>\n",
              "      <th>documentType</th>\n",
              "      <th>headline</th>\n",
              "      <th>keywords</th>\n",
              "      <th>multimedia</th>\n",
              "      <th>newDesk</th>\n",
              "      <th>printPage</th>\n",
              "      <th>pubDate</th>\n",
              "      <th>sectionName</th>\n",
              "      <th>snippet</th>\n",
              "      <th>source</th>\n",
              "      <th>typeOfMaterial</th>\n",
              "      <th>webURL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5adf6684068401528a2aa69b</td>\n",
              "      <td>781</td>\n",
              "      <td>By JOHN BRANCH</td>\n",
              "      <td>article</td>\n",
              "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
              "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
              "      <td>68</td>\n",
              "      <td>Sports</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:16:49</td>\n",
              "      <td>Pro Football</td>\n",
              "      <td>“I understand that they could meet with us, pa...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5adf653f068401528a2aa697</td>\n",
              "      <td>656</td>\n",
              "      <td>By LISA FRIEDMAN</td>\n",
              "      <td>article</td>\n",
              "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
              "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
              "      <td>68</td>\n",
              "      <td>Climate</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:11:21</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>The agency plans to publish a new regulation T...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5adf4626068401528a2aa628</td>\n",
              "      <td>2427</td>\n",
              "      <td>By PETE WELLS</td>\n",
              "      <td>article</td>\n",
              "      <td>The New Noma, Explained</td>\n",
              "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
              "      <td>66</td>\n",
              "      <td>Dining</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:58:44</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>What’s it like to eat at the second incarnatio...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5adf40d2068401528a2aa619</td>\n",
              "      <td>626</td>\n",
              "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
              "      <td>68</td>\n",
              "      <td>Washington</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:35:57</td>\n",
              "      <td>Europe</td>\n",
              "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5adf3d64068401528a2aa60f</td>\n",
              "      <td>815</td>\n",
              "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
              "      <td>68</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:21:21</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  articleID  ...                                             webURL\n",
              "0  5adf6684068401528a2aa69b  ...  https://www.nytimes.com/2018/04/24/sports/foot...\n",
              "1  5adf653f068401528a2aa697  ...  https://www.nytimes.com/2018/04/24/climate/epa...\n",
              "2  5adf4626068401528a2aa628  ...  https://www.nytimes.com/2018/04/24/dining/noma...\n",
              "3  5adf40d2068401528a2aa619  ...  https://www.nytimes.com/2018/04/24/world/europ...\n",
              "4  5adf3d64068401528a2aa60f  ...  https://www.nytimes.com/2018/04/24/world/canad...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGISS0sh6z2a",
        "outputId": "ed93961e-9d92-49ae-ff53-21ff9d849582"
      },
      "source": [
        "print('열의 개수: ',len(df.columns))\n",
        "print(df.columns)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "열의 개수:  15\n",
            "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
            "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
            "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4KodBsC69Jf",
        "outputId": "051a93b5-555f-48d5-aa62-01d573eee96a"
      },
      "source": [
        "df['headline'].isnull().values.any()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggX9LXF-7AgP",
        "outputId": "4ff9dbbd-85cd-4c7a-e146-f9cc9a4b3b43"
      },
      "source": [
        "headline = [] \n",
        "headline.extend(list(df.headline.values))\n",
        "headline[:5] "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'Unknown',\n",
              " 'Unknown']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNeWhJ2m7Mzs",
        "outputId": "61d4c3fb-e045-4a46-d9b1-88094a5ac6df"
      },
      "source": [
        "print('총 샘플의 개수 : {}'.format(len(headline)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 샘플의 개수 : 1324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujcPRAi27QRU",
        "outputId": "e551ad00-ef29-48c8-f5c9-e7c4380583fb"
      },
      "source": [
        "headline = [n for n in headline if n != \"Unknown\"] \n",
        "print('노이즈값 제거 후 샘플의 개수 : {}'.format(len(headline)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "노이즈값 제거 후 샘플의 개수 : 1214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8fgpVnu7S-7",
        "outputId": "76343360-e6e5-48ca-c9cb-a9382f411ade"
      },
      "source": [
        "headline[:5]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
              " 'Is School a Place for Self-Expression?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN4K2Q717VXt",
        "outputId": "d024cd04-28bb-46c5-a4bd-94fcd0007a76"
      },
      "source": [
        "def repreprocessing(s):\n",
        "    s=s.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return ''.join(c for c in s if c not in punctuation).lower() # 구두점 제거와 동시에 소문자화\n",
        "\n",
        "text = [repreprocessing(x) for x in headline]\n",
        "text[:5]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
              " 'epa to unveil a new rule its effect less science in policymaking',\n",
              " 'the new noma explained',\n",
              " 'how a bag of texas dirt  became a times tradition',\n",
              " 'is school a place for selfexpression']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU3TGuy77gRF",
        "outputId": "0dc942b5-d0c6-4112-9386-0771cbab2041"
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(text)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "print('단어 집합의 크기 : %d' % vocab_size)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 3494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8exeHSs7i-U",
        "outputId": "6931551e-e97a-4736-f706-3e580a4c758f"
      },
      "source": [
        "sequences = list()\n",
        "\n",
        "for line in text: \n",
        "    encoded = t.texts_to_sequences([line])[0] \n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "sequences[:11]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[99, 269],\n",
              " [99, 269, 371],\n",
              " [99, 269, 371, 1115],\n",
              " [99, 269, 371, 1115, 582],\n",
              " [99, 269, 371, 1115, 582, 52],\n",
              " [99, 269, 371, 1115, 582, 52, 7],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
              " [100, 3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkGoh_p47pR0",
        "outputId": "0d09951d-62b6-40ff-d46a-82c813b7c9aa"
      },
      "source": [
        "index_to_word={}\n",
        "for key, value in t.word_index.items(): \n",
        "    index_to_word[value] = key\n",
        "\n",
        "print('빈도수 상위 100번 단어 : {}'.format(index_to_word[100]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "빈도수 상위 100번 단어 : epa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab7C4EeY72qz",
        "outputId": "e76f93dd-22bc-4134-943a-61dcab5f9769"
      },
      "source": [
        "max_len=max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 : {}'.format(max_len))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "샘플의 최대 길이 : 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5GOPyin75zq",
        "outputId": "2d74fc6a-6bfe-4da4-e902-f4feefd2602d"
      },
      "source": [
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "print(sequences[:3])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0   99  269]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0   99  269  371]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0   99  269  371 1115]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svIN6XvD77-R"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm7gUrxB7-94"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkoJmu5f8A0E"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbc-RECT8DhB",
        "outputId": "592841c3-e6c6-4ce6-f0c7-60bfe294ced6"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=max_len-1))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=200, verbose=2)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "244/244 - 7s - loss: 7.6335 - accuracy: 0.0259\n",
            "Epoch 2/200\n",
            "244/244 - 7s - loss: 7.1076 - accuracy: 0.0288\n",
            "Epoch 3/200\n",
            "244/244 - 7s - loss: 6.9680 - accuracy: 0.0314\n",
            "Epoch 4/200\n",
            "244/244 - 7s - loss: 6.8389 - accuracy: 0.0408\n",
            "Epoch 5/200\n",
            "244/244 - 7s - loss: 6.6876 - accuracy: 0.0436\n",
            "Epoch 6/200\n",
            "244/244 - 7s - loss: 6.5193 - accuracy: 0.0481\n",
            "Epoch 7/200\n",
            "244/244 - 7s - loss: 6.3244 - accuracy: 0.0538\n",
            "Epoch 8/200\n",
            "244/244 - 7s - loss: 6.1221 - accuracy: 0.0590\n",
            "Epoch 9/200\n",
            "244/244 - 7s - loss: 5.9242 - accuracy: 0.0642\n",
            "Epoch 10/200\n",
            "244/244 - 7s - loss: 5.7313 - accuracy: 0.0681\n",
            "Epoch 11/200\n",
            "244/244 - 7s - loss: 5.5495 - accuracy: 0.0734\n",
            "Epoch 12/200\n",
            "244/244 - 7s - loss: 5.3800 - accuracy: 0.0759\n",
            "Epoch 13/200\n",
            "244/244 - 7s - loss: 5.2189 - accuracy: 0.0847\n",
            "Epoch 14/200\n",
            "244/244 - 7s - loss: 5.0664 - accuracy: 0.0897\n",
            "Epoch 15/200\n",
            "244/244 - 7s - loss: 4.9198 - accuracy: 0.1001\n",
            "Epoch 16/200\n",
            "244/244 - 7s - loss: 4.7811 - accuracy: 0.1098\n",
            "Epoch 17/200\n",
            "244/244 - 7s - loss: 4.6471 - accuracy: 0.1256\n",
            "Epoch 18/200\n",
            "244/244 - 7s - loss: 4.5188 - accuracy: 0.1374\n",
            "Epoch 19/200\n",
            "244/244 - 7s - loss: 4.3925 - accuracy: 0.1561\n",
            "Epoch 20/200\n",
            "244/244 - 7s - loss: 4.2723 - accuracy: 0.1712\n",
            "Epoch 21/200\n",
            "244/244 - 7s - loss: 4.1508 - accuracy: 0.1918\n",
            "Epoch 22/200\n",
            "244/244 - 7s - loss: 4.0384 - accuracy: 0.2045\n",
            "Epoch 23/200\n",
            "244/244 - 7s - loss: 3.9315 - accuracy: 0.2215\n",
            "Epoch 24/200\n",
            "244/244 - 7s - loss: 3.8255 - accuracy: 0.2379\n",
            "Epoch 25/200\n",
            "244/244 - 7s - loss: 3.7232 - accuracy: 0.2567\n",
            "Epoch 26/200\n",
            "244/244 - 7s - loss: 3.6226 - accuracy: 0.2725\n",
            "Epoch 27/200\n",
            "244/244 - 7s - loss: 3.5300 - accuracy: 0.2905\n",
            "Epoch 28/200\n",
            "244/244 - 7s - loss: 3.4374 - accuracy: 0.3083\n",
            "Epoch 29/200\n",
            "244/244 - 7s - loss: 3.3473 - accuracy: 0.3185\n",
            "Epoch 30/200\n",
            "244/244 - 7s - loss: 3.2619 - accuracy: 0.3394\n",
            "Epoch 31/200\n",
            "244/244 - 7s - loss: 3.1765 - accuracy: 0.3565\n",
            "Epoch 32/200\n",
            "244/244 - 7s - loss: 3.0975 - accuracy: 0.3702\n",
            "Epoch 33/200\n",
            "244/244 - 7s - loss: 3.0220 - accuracy: 0.3851\n",
            "Epoch 34/200\n",
            "244/244 - 7s - loss: 2.9457 - accuracy: 0.3947\n",
            "Epoch 35/200\n",
            "244/244 - 7s - loss: 2.8756 - accuracy: 0.4110\n",
            "Epoch 36/200\n",
            "244/244 - 7s - loss: 2.8043 - accuracy: 0.4251\n",
            "Epoch 37/200\n",
            "244/244 - 7s - loss: 2.7415 - accuracy: 0.4357\n",
            "Epoch 38/200\n",
            "244/244 - 7s - loss: 2.6725 - accuracy: 0.4492\n",
            "Epoch 39/200\n",
            "244/244 - 7s - loss: 2.6109 - accuracy: 0.4642\n",
            "Epoch 40/200\n",
            "244/244 - 7s - loss: 2.5490 - accuracy: 0.4712\n",
            "Epoch 41/200\n",
            "244/244 - 7s - loss: 2.4904 - accuracy: 0.4852\n",
            "Epoch 42/200\n",
            "244/244 - 7s - loss: 2.4327 - accuracy: 0.4970\n",
            "Epoch 43/200\n",
            "244/244 - 7s - loss: 2.3770 - accuracy: 0.5076\n",
            "Epoch 44/200\n",
            "244/244 - 7s - loss: 2.3242 - accuracy: 0.5222\n",
            "Epoch 45/200\n",
            "244/244 - 7s - loss: 2.2687 - accuracy: 0.5293\n",
            "Epoch 46/200\n",
            "244/244 - 7s - loss: 2.2187 - accuracy: 0.5374\n",
            "Epoch 47/200\n",
            "244/244 - 7s - loss: 2.1660 - accuracy: 0.5495\n",
            "Epoch 48/200\n",
            "244/244 - 7s - loss: 2.1177 - accuracy: 0.5609\n",
            "Epoch 49/200\n",
            "244/244 - 7s - loss: 2.0671 - accuracy: 0.5718\n",
            "Epoch 50/200\n",
            "244/244 - 7s - loss: 2.0237 - accuracy: 0.5805\n",
            "Epoch 51/200\n",
            "244/244 - 7s - loss: 1.9791 - accuracy: 0.5936\n",
            "Epoch 52/200\n",
            "244/244 - 7s - loss: 1.9302 - accuracy: 0.6044\n",
            "Epoch 53/200\n",
            "244/244 - 7s - loss: 1.8904 - accuracy: 0.6128\n",
            "Epoch 54/200\n",
            "244/244 - 7s - loss: 1.8453 - accuracy: 0.6199\n",
            "Epoch 55/200\n",
            "244/244 - 7s - loss: 1.8017 - accuracy: 0.6318\n",
            "Epoch 56/200\n",
            "244/244 - 7s - loss: 1.7586 - accuracy: 0.6405\n",
            "Epoch 57/200\n",
            "244/244 - 7s - loss: 1.7205 - accuracy: 0.6503\n",
            "Epoch 58/200\n",
            "244/244 - 7s - loss: 1.6820 - accuracy: 0.6565\n",
            "Epoch 59/200\n",
            "244/244 - 7s - loss: 1.6430 - accuracy: 0.6667\n",
            "Epoch 60/200\n",
            "244/244 - 7s - loss: 1.6020 - accuracy: 0.6759\n",
            "Epoch 61/200\n",
            "244/244 - 7s - loss: 1.5676 - accuracy: 0.6805\n",
            "Epoch 62/200\n",
            "244/244 - 7s - loss: 1.5312 - accuracy: 0.6901\n",
            "Epoch 63/200\n",
            "244/244 - 7s - loss: 1.4947 - accuracy: 0.6947\n",
            "Epoch 64/200\n",
            "244/244 - 7s - loss: 1.4588 - accuracy: 0.7050\n",
            "Epoch 65/200\n",
            "244/244 - 7s - loss: 1.4214 - accuracy: 0.7142\n",
            "Epoch 66/200\n",
            "244/244 - 7s - loss: 1.3891 - accuracy: 0.7216\n",
            "Epoch 67/200\n",
            "244/244 - 7s - loss: 1.3594 - accuracy: 0.7256\n",
            "Epoch 68/200\n",
            "244/244 - 7s - loss: 1.3254 - accuracy: 0.7346\n",
            "Epoch 69/200\n",
            "244/244 - 10s - loss: 1.2933 - accuracy: 0.7380\n",
            "Epoch 70/200\n",
            "244/244 - 8s - loss: 1.2648 - accuracy: 0.7437\n",
            "Epoch 71/200\n",
            "244/244 - 7s - loss: 1.2353 - accuracy: 0.7515\n",
            "Epoch 72/200\n",
            "244/244 - 7s - loss: 1.2048 - accuracy: 0.7597\n",
            "Epoch 73/200\n",
            "244/244 - 7s - loss: 1.1749 - accuracy: 0.7657\n",
            "Epoch 74/200\n",
            "244/244 - 7s - loss: 1.1482 - accuracy: 0.7702\n",
            "Epoch 75/200\n",
            "244/244 - 7s - loss: 1.1195 - accuracy: 0.7800\n",
            "Epoch 76/200\n",
            "244/244 - 7s - loss: 1.0924 - accuracy: 0.7834\n",
            "Epoch 77/200\n",
            "244/244 - 7s - loss: 1.0699 - accuracy: 0.7862\n",
            "Epoch 78/200\n",
            "244/244 - 7s - loss: 1.0424 - accuracy: 0.7917\n",
            "Epoch 79/200\n",
            "244/244 - 7s - loss: 1.0186 - accuracy: 0.7974\n",
            "Epoch 80/200\n",
            "244/244 - 7s - loss: 0.9938 - accuracy: 0.8026\n",
            "Epoch 81/200\n",
            "244/244 - 7s - loss: 0.9710 - accuracy: 0.8047\n",
            "Epoch 82/200\n",
            "244/244 - 7s - loss: 0.9471 - accuracy: 0.8133\n",
            "Epoch 83/200\n",
            "244/244 - 7s - loss: 0.9242 - accuracy: 0.8165\n",
            "Epoch 84/200\n",
            "244/244 - 7s - loss: 0.9048 - accuracy: 0.8161\n",
            "Epoch 85/200\n",
            "244/244 - 7s - loss: 0.8825 - accuracy: 0.8248\n",
            "Epoch 86/200\n",
            "244/244 - 7s - loss: 0.8635 - accuracy: 0.8274\n",
            "Epoch 87/200\n",
            "244/244 - 7s - loss: 0.8444 - accuracy: 0.8310\n",
            "Epoch 88/200\n",
            "244/244 - 7s - loss: 0.8290 - accuracy: 0.8366\n",
            "Epoch 89/200\n",
            "244/244 - 7s - loss: 0.8045 - accuracy: 0.8406\n",
            "Epoch 90/200\n",
            "244/244 - 7s - loss: 0.7875 - accuracy: 0.8434\n",
            "Epoch 91/200\n",
            "244/244 - 7s - loss: 0.7675 - accuracy: 0.8453\n",
            "Epoch 92/200\n",
            "244/244 - 7s - loss: 0.7502 - accuracy: 0.8495\n",
            "Epoch 93/200\n",
            "244/244 - 7s - loss: 0.7359 - accuracy: 0.8526\n",
            "Epoch 94/200\n",
            "244/244 - 7s - loss: 0.7193 - accuracy: 0.8536\n",
            "Epoch 95/200\n",
            "244/244 - 7s - loss: 0.7021 - accuracy: 0.8590\n",
            "Epoch 96/200\n",
            "244/244 - 7s - loss: 0.6884 - accuracy: 0.8620\n",
            "Epoch 97/200\n",
            "244/244 - 7s - loss: 0.6779 - accuracy: 0.8659\n",
            "Epoch 98/200\n",
            "244/244 - 7s - loss: 0.6589 - accuracy: 0.8677\n",
            "Epoch 99/200\n",
            "244/244 - 7s - loss: 0.6452 - accuracy: 0.8709\n",
            "Epoch 100/200\n",
            "244/244 - 7s - loss: 0.6322 - accuracy: 0.8688\n",
            "Epoch 101/200\n",
            "244/244 - 7s - loss: 0.6180 - accuracy: 0.8742\n",
            "Epoch 102/200\n",
            "244/244 - 7s - loss: 0.6067 - accuracy: 0.8770\n",
            "Epoch 103/200\n",
            "244/244 - 7s - loss: 0.5923 - accuracy: 0.8803\n",
            "Epoch 104/200\n",
            "244/244 - 7s - loss: 0.5793 - accuracy: 0.8830\n",
            "Epoch 105/200\n",
            "244/244 - 7s - loss: 0.5694 - accuracy: 0.8844\n",
            "Epoch 106/200\n",
            "244/244 - 7s - loss: 0.5597 - accuracy: 0.8857\n",
            "Epoch 107/200\n",
            "244/244 - 7s - loss: 0.5460 - accuracy: 0.8884\n",
            "Epoch 108/200\n",
            "244/244 - 7s - loss: 0.5415 - accuracy: 0.8874\n",
            "Epoch 109/200\n",
            "244/244 - 7s - loss: 0.5261 - accuracy: 0.8904\n",
            "Epoch 110/200\n",
            "244/244 - 7s - loss: 0.5129 - accuracy: 0.8912\n",
            "Epoch 111/200\n",
            "244/244 - 7s - loss: 0.5021 - accuracy: 0.8958\n",
            "Epoch 112/200\n",
            "244/244 - 7s - loss: 0.4934 - accuracy: 0.8963\n",
            "Epoch 113/200\n",
            "244/244 - 7s - loss: 0.4877 - accuracy: 0.8980\n",
            "Epoch 114/200\n",
            "244/244 - 7s - loss: 0.5005 - accuracy: 0.8971\n",
            "Epoch 115/200\n",
            "244/244 - 7s - loss: 0.4739 - accuracy: 0.8989\n",
            "Epoch 116/200\n",
            "244/244 - 7s - loss: 0.4630 - accuracy: 0.9023\n",
            "Epoch 117/200\n",
            "244/244 - 7s - loss: 0.4527 - accuracy: 0.9039\n",
            "Epoch 118/200\n",
            "244/244 - 7s - loss: 0.4448 - accuracy: 0.9027\n",
            "Epoch 119/200\n",
            "244/244 - 7s - loss: 0.4385 - accuracy: 0.9039\n",
            "Epoch 120/200\n",
            "244/244 - 7s - loss: 0.4300 - accuracy: 0.9063\n",
            "Epoch 121/200\n",
            "244/244 - 7s - loss: 0.4240 - accuracy: 0.9049\n",
            "Epoch 122/200\n",
            "244/244 - 7s - loss: 0.4208 - accuracy: 0.9089\n",
            "Epoch 123/200\n",
            "244/244 - 7s - loss: 0.4136 - accuracy: 0.9080\n",
            "Epoch 124/200\n",
            "244/244 - 7s - loss: 0.4111 - accuracy: 0.9075\n",
            "Epoch 125/200\n",
            "244/244 - 7s - loss: 0.4049 - accuracy: 0.9090\n",
            "Epoch 126/200\n",
            "244/244 - 7s - loss: 0.3937 - accuracy: 0.9109\n",
            "Epoch 127/200\n",
            "244/244 - 7s - loss: 0.3862 - accuracy: 0.9123\n",
            "Epoch 128/200\n",
            "244/244 - 7s - loss: 0.3836 - accuracy: 0.9129\n",
            "Epoch 129/200\n",
            "244/244 - 7s - loss: 0.3770 - accuracy: 0.9116\n",
            "Epoch 130/200\n",
            "244/244 - 7s - loss: 0.3702 - accuracy: 0.9132\n",
            "Epoch 131/200\n",
            "244/244 - 7s - loss: 0.3685 - accuracy: 0.9129\n",
            "Epoch 132/200\n",
            "244/244 - 7s - loss: 0.3643 - accuracy: 0.9135\n",
            "Epoch 133/200\n",
            "244/244 - 7s - loss: 0.3620 - accuracy: 0.9135\n",
            "Epoch 134/200\n",
            "244/244 - 7s - loss: 0.3541 - accuracy: 0.9157\n",
            "Epoch 135/200\n",
            "244/244 - 7s - loss: 0.3496 - accuracy: 0.9135\n",
            "Epoch 136/200\n",
            "244/244 - 7s - loss: 0.3456 - accuracy: 0.9141\n",
            "Epoch 137/200\n",
            "244/244 - 7s - loss: 0.3401 - accuracy: 0.9153\n",
            "Epoch 138/200\n",
            "244/244 - 7s - loss: 0.3378 - accuracy: 0.9143\n",
            "Epoch 139/200\n",
            "244/244 - 7s - loss: 0.3392 - accuracy: 0.9153\n",
            "Epoch 140/200\n",
            "244/244 - 7s - loss: 0.3452 - accuracy: 0.9149\n",
            "Epoch 141/200\n",
            "244/244 - 7s - loss: 0.3333 - accuracy: 0.9162\n",
            "Epoch 142/200\n",
            "244/244 - 7s - loss: 0.3249 - accuracy: 0.9152\n",
            "Epoch 143/200\n",
            "244/244 - 7s - loss: 0.3204 - accuracy: 0.9159\n",
            "Epoch 144/200\n",
            "244/244 - 7s - loss: 0.3190 - accuracy: 0.9149\n",
            "Epoch 145/200\n",
            "244/244 - 7s - loss: 0.3161 - accuracy: 0.9164\n",
            "Epoch 146/200\n",
            "244/244 - 7s - loss: 0.3152 - accuracy: 0.9150\n",
            "Epoch 147/200\n",
            "244/244 - 7s - loss: 0.3107 - accuracy: 0.9167\n",
            "Epoch 148/200\n",
            "244/244 - 7s - loss: 0.3093 - accuracy: 0.9155\n",
            "Epoch 149/200\n",
            "244/244 - 7s - loss: 0.3136 - accuracy: 0.9168\n",
            "Epoch 150/200\n",
            "244/244 - 7s - loss: 0.3076 - accuracy: 0.9153\n",
            "Epoch 151/200\n",
            "244/244 - 7s - loss: 0.3025 - accuracy: 0.9167\n",
            "Epoch 152/200\n",
            "244/244 - 7s - loss: 0.3026 - accuracy: 0.9146\n",
            "Epoch 153/200\n",
            "244/244 - 7s - loss: 0.2991 - accuracy: 0.9170\n",
            "Epoch 154/200\n",
            "244/244 - 7s - loss: 0.2959 - accuracy: 0.9167\n",
            "Epoch 155/200\n",
            "244/244 - 7s - loss: 0.2955 - accuracy: 0.9162\n",
            "Epoch 156/200\n",
            "244/244 - 7s - loss: 0.2924 - accuracy: 0.9158\n",
            "Epoch 157/200\n",
            "244/244 - 7s - loss: 0.2930 - accuracy: 0.9166\n",
            "Epoch 158/200\n",
            "244/244 - 7s - loss: 0.3133 - accuracy: 0.9126\n",
            "Epoch 159/200\n",
            "244/244 - 7s - loss: 0.3146 - accuracy: 0.9117\n",
            "Epoch 160/200\n",
            "244/244 - 7s - loss: 0.2966 - accuracy: 0.9167\n",
            "Epoch 161/200\n",
            "244/244 - 7s - loss: 0.2872 - accuracy: 0.9176\n",
            "Epoch 162/200\n",
            "244/244 - 7s - loss: 0.2840 - accuracy: 0.9167\n",
            "Epoch 163/200\n",
            "244/244 - 7s - loss: 0.2831 - accuracy: 0.9168\n",
            "Epoch 164/200\n",
            "244/244 - 7s - loss: 0.2821 - accuracy: 0.9153\n",
            "Epoch 165/200\n",
            "244/244 - 7s - loss: 0.2820 - accuracy: 0.9167\n",
            "Epoch 166/200\n",
            "244/244 - 7s - loss: 0.2801 - accuracy: 0.9167\n",
            "Epoch 167/200\n",
            "244/244 - 7s - loss: 0.2891 - accuracy: 0.9166\n",
            "Epoch 168/200\n",
            "244/244 - 7s - loss: 0.2812 - accuracy: 0.9153\n",
            "Epoch 169/200\n",
            "244/244 - 7s - loss: 0.2784 - accuracy: 0.9164\n",
            "Epoch 170/200\n",
            "244/244 - 7s - loss: 0.2774 - accuracy: 0.9161\n",
            "Epoch 171/200\n",
            "244/244 - 7s - loss: 0.2757 - accuracy: 0.9166\n",
            "Epoch 172/200\n",
            "244/244 - 7s - loss: 0.2753 - accuracy: 0.9157\n",
            "Epoch 173/200\n",
            "244/244 - 7s - loss: 0.2742 - accuracy: 0.9161\n",
            "Epoch 174/200\n",
            "244/244 - 7s - loss: 0.2748 - accuracy: 0.9171\n",
            "Epoch 175/200\n",
            "244/244 - 7s - loss: 0.2732 - accuracy: 0.9167\n",
            "Epoch 176/200\n",
            "244/244 - 7s - loss: 0.2732 - accuracy: 0.9155\n",
            "Epoch 177/200\n",
            "244/244 - 7s - loss: 0.2740 - accuracy: 0.9168\n",
            "Epoch 178/200\n",
            "244/244 - 7s - loss: 0.2744 - accuracy: 0.9168\n",
            "Epoch 179/200\n",
            "244/244 - 7s - loss: 0.2769 - accuracy: 0.9164\n",
            "Epoch 180/200\n",
            "244/244 - 7s - loss: 0.2739 - accuracy: 0.9157\n",
            "Epoch 181/200\n",
            "244/244 - 7s - loss: 0.2758 - accuracy: 0.9161\n",
            "Epoch 182/200\n",
            "244/244 - 7s - loss: 0.2745 - accuracy: 0.9145\n",
            "Epoch 183/200\n",
            "244/244 - 7s - loss: 0.2706 - accuracy: 0.9143\n",
            "Epoch 184/200\n",
            "244/244 - 7s - loss: 0.2673 - accuracy: 0.9168\n",
            "Epoch 185/200\n",
            "244/244 - 7s - loss: 0.2671 - accuracy: 0.9180\n",
            "Epoch 186/200\n",
            "244/244 - 7s - loss: 0.2665 - accuracy: 0.9168\n",
            "Epoch 187/200\n",
            "244/244 - 7s - loss: 0.2661 - accuracy: 0.9157\n",
            "Epoch 188/200\n",
            "244/244 - 7s - loss: 0.2717 - accuracy: 0.9154\n",
            "Epoch 189/200\n",
            "244/244 - 7s - loss: 5.7497 - accuracy: 0.3496\n",
            "Epoch 190/200\n",
            "244/244 - 7s - loss: 0.4842 - accuracy: 0.8679\n",
            "Epoch 191/200\n",
            "244/244 - 7s - loss: 0.2998 - accuracy: 0.9149\n",
            "Epoch 192/200\n",
            "244/244 - 7s - loss: 0.2774 - accuracy: 0.9166\n",
            "Epoch 193/200\n",
            "244/244 - 7s - loss: 0.2725 - accuracy: 0.9161\n",
            "Epoch 194/200\n",
            "244/244 - 7s - loss: 0.2706 - accuracy: 0.9177\n",
            "Epoch 195/200\n",
            "244/244 - 7s - loss: 0.2678 - accuracy: 0.9176\n",
            "Epoch 196/200\n",
            "244/244 - 7s - loss: 0.2670 - accuracy: 0.9170\n",
            "Epoch 197/200\n",
            "244/244 - 7s - loss: 0.2657 - accuracy: 0.9177\n",
            "Epoch 198/200\n",
            "244/244 - 7s - loss: 0.2655 - accuracy: 0.9171\n",
            "Epoch 199/200\n",
            "244/244 - 7s - loss: 0.2647 - accuracy: 0.9157\n",
            "Epoch 200/200\n",
            "244/244 - 7s - loss: 0.2644 - accuracy: 0.9158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3460a11588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA1u9rUH8eRz"
      },
      "source": [
        "def sentence_generation(model, t, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
        "    sentence = ''\n",
        "    for _ in range(n): # n번 반복\n",
        "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\n",
        "        encoded = pad_sequences([encoded], maxlen=23, padding='pre') # 데이터에 대한 패딩\n",
        "        result = model.predict_classes(encoded, verbose=0)\n",
        "    # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
        "        for word, index in t.word_index.items(): \n",
        "            if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "                break # 해당 단어가 예측 단어이므로 break\n",
        "        current_word = current_word + ' '  + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\n",
        "    # for문이므로 이 행동을 다시 반복\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bMwNjpI8guD",
        "outputId": "9a809783-7fd2-49ee-d392-50a86af60644"
      },
      "source": [
        "print(sentence_generation(model, t, 'i', 10))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i want to be rich and im not sorry think hes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wELcKzhO8ijw",
        "outputId": "22f689de-025f-41f3-c93d-df221401a585"
      },
      "source": [
        "print(sentence_generation(model, t, 'how', 10))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "how to win an argument about guns hair gop can case\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}