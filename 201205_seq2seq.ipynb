{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "201205_seq2seq.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPl/bMdAl93CA44AGsqcRRE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoonYoung-Sohn/practice/blob/master/201205_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00Q-4puee11L"
      },
      "source": [
        "seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyjq3dVtHmEQ"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib3\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6bG86cRZgzw"
      },
      "source": [
        "http = urllib3.PoolManager()\n",
        "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = 'fra-eng.zip'\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, filename)\n",
        "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
        "    shutil.copyfileobj(r, out_file)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLsrzZBRZlfW",
        "outputId": "308970d8-8aeb-4579-8088-910a42b1cdb0"
      },
      "source": [
        "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
        "del lines['lic']\n",
        "len(lines)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "nEXqmXn3Zncg",
        "outputId": "c3f4bf42-024a-46a5-9fb1-a0aa7668835d"
      },
      "source": [
        "lines = lines.loc[:, 'src':'tar']\n",
        "lines = lines[0:60000]\n",
        "lines.sample(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6805</th>\n",
              "      <td>Straighten up.</td>\n",
              "      <td>Redresse-toi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6775</th>\n",
              "      <td>Start writing.</td>\n",
              "      <td>Commencez à écrire.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31924</th>\n",
              "      <td>It's a real bargain.</td>\n",
              "      <td>C'est une bonne affaire.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41556</th>\n",
              "      <td>Did he propose to you?</td>\n",
              "      <td>T'a-t-il demandée en mariage ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40796</th>\n",
              "      <td>You don't have to go.</td>\n",
              "      <td>Vous n'êtes pas forcées de vous en aller.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30006</th>\n",
              "      <td>He lacks confidence.</td>\n",
              "      <td>Il manque de confiance.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20525</th>\n",
              "      <td>I was embarrassed.</td>\n",
              "      <td>J'étais embarrassé.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56084</th>\n",
              "      <td>I cannot possibly do it.</td>\n",
              "      <td>Il m’est impossible de le faire.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34377</th>\n",
              "      <td>You can rely on him.</td>\n",
              "      <td>On peut se fier à lui.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39293</th>\n",
              "      <td>They paid separately.</td>\n",
              "      <td>Elles ont payé séparément.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            src                                        tar\n",
              "6805             Straighten up.                              Redresse-toi.\n",
              "6775             Start writing.                        Commencez à écrire.\n",
              "31924      It's a real bargain.                   C'est une bonne affaire.\n",
              "41556    Did he propose to you?             T'a-t-il demandée en mariage ?\n",
              "40796     You don't have to go.  Vous n'êtes pas forcées de vous en aller.\n",
              "30006      He lacks confidence.                    Il manque de confiance.\n",
              "20525        I was embarrassed.                        J'étais embarrassé.\n",
              "56084  I cannot possibly do it.           Il m’est impossible de le faire.\n",
              "34377      You can rely on him.                     On peut se fier à lui.\n",
              "39293     They paid separately.                 Elles ont payé séparément."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "XwFRROIvZ8ZC",
        "outputId": "1922db66-f327-4ee9-ef5f-eaae90f75a64"
      },
      "source": [
        "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
        "lines.sample(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50794</th>\n",
              "      <td>I'm not totally stupid.</td>\n",
              "      <td>\\t Je ne suis pas complètement bête ! \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36695</th>\n",
              "      <td>I have such bad luck.</td>\n",
              "      <td>\\t J'ai une telle poisse ! \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52497</th>\n",
              "      <td>They must be Americans.</td>\n",
              "      <td>\\t Ils doivent être américains. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39584</th>\n",
              "      <td>Tom became indignant.</td>\n",
              "      <td>\\t Tom s'est indigné. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42642</th>\n",
              "      <td>How much is this sofa?</td>\n",
              "      <td>\\t Combien coûte ce canapé ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43051</th>\n",
              "      <td>I feel like a new man.</td>\n",
              "      <td>\\t Je me sens comme un homme nouveau. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43575</th>\n",
              "      <td>I really want to stay.</td>\n",
              "      <td>\\t Je veux vraiment rester. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23361</th>\n",
              "      <td>You have to leave.</td>\n",
              "      <td>\\t Vous devez partir. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44691</th>\n",
              "      <td>It's not looking good.</td>\n",
              "      <td>\\t Ça ne se présente pas bien. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24550</th>\n",
              "      <td>He is sharp-witted.</td>\n",
              "      <td>\\t Il a l'esprit vif. \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           src                                       tar\n",
              "50794  I'm not totally stupid.  \\t Je ne suis pas complètement bête ! \\n\n",
              "36695    I have such bad luck.             \\t J'ai une telle poisse ! \\n\n",
              "52497  They must be Americans.        \\t Ils doivent être américains. \\n\n",
              "39584    Tom became indignant.                  \\t Tom s'est indigné. \\n\n",
              "42642   How much is this sofa?           \\t Combien coûte ce canapé ? \\n\n",
              "43051   I feel like a new man.  \\t Je me sens comme un homme nouveau. \\n\n",
              "43575   I really want to stay.            \\t Je veux vraiment rester. \\n\n",
              "23361       You have to leave.                  \\t Vous devez partir. \\n\n",
              "44691   It's not looking good.         \\t Ça ne se présente pas bien. \\n\n",
              "24550      He is sharp-witted.                  \\t Il a l'esprit vif. \\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuJjfAQ-aXkh"
      },
      "source": [
        "src_vocab=set()\n",
        "for line in lines.src: \n",
        "    for char in line:\n",
        "        src_vocab.add(char)\n",
        "\n",
        "tar_vocab=set()\n",
        "for line in lines.tar:\n",
        "    for char in line:\n",
        "        tar_vocab.add(char)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVTLEzBXbdzu",
        "outputId": "d56f5b1b-218c-4ba2-f49e-1926db549d49"
      },
      "source": [
        "src_vocab_size = len(src_vocab)+1\n",
        "tar_vocab_size = len(tar_vocab)+1\n",
        "print(src_vocab_size)\n",
        "print(tar_vocab_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79\n",
            "106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywe0XXjLb8ML",
        "outputId": "0a8db8a9-2bc2-4f51-d7e7-1bf69a13a6d8"
      },
      "source": [
        "src_vocab = sorted(list(src_vocab))\n",
        "tar_vocab = sorted(list(tar_vocab))\n",
        "print(src_vocab[45:75])\n",
        "print(tar_vocab[45:75])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6EBGgbBc44q",
        "outputId": "b5902ee4-a2ff-470c-e4d0-74db14ec5cb1"
      },
      "source": [
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "print(src_to_index)\n",
        "print(tar_to_index)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n",
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, 'С': 100, '\\u2009': 101, '\\u200b': 102, '‘': 103, '’': 104, '\\u202f': 105}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bZFWW4HdAMf",
        "outputId": "6673fbc6-2b37-4dc1-f81e-9f392c0d7b4a"
      },
      "source": [
        "encoder_input = []\n",
        "for line in lines.src: \n",
        "    temp_X = []\n",
        "    for w in line: \n",
        "      temp_X.append(src_to_index[w]) \n",
        "    encoder_input.append(temp_X)\n",
        "print(encoder_input[:5])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[30, 64, 10], [31, 58, 10], [31, 58, 10], [41, 70, 63, 2], [41, 70, 63, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX5cTZghdKHV",
        "outputId": "3936da24-e457-485a-ad33-372380c31f38"
      },
      "source": [
        "decoder_input = []\n",
        "for line in lines.tar:\n",
        "    temp_X = []\n",
        "    for w in line:\n",
        "      temp_X.append(tar_to_index[w])\n",
        "    decoder_input.append(temp_X)\n",
        "print(decoder_input[:5])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 3, 48, 53, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 14, 3, 2], [1, 3, 29, 67, 73, 70, 71, 105, 4, 3, 2], [1, 3, 29, 67, 73, 70, 57, 78, 105, 4, 3, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVx990Xcdekl",
        "outputId": "04942b1d-0b94-4218-d297-9ffd3fa3ceec"
      },
      "source": [
        "decoder_target = []\n",
        "for line in lines.tar:\n",
        "    t=0\n",
        "    temp_X = []\n",
        "    for w in line:\n",
        "      if t>0:\n",
        "        temp_X.append(tar_to_index[w])\n",
        "      t=t+1\n",
        "    decoder_target.append(temp_X)\n",
        "print(decoder_target[:5])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 48, 53, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 14, 3, 2], [3, 29, 67, 73, 70, 71, 105, 4, 3, 2], [3, 29, 67, 73, 70, 57, 78, 105, 4, 3, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWzbNqhVdnpe",
        "outputId": "0d9604e1-dc67-42d9-c94a-efa75b12b57c"
      },
      "source": [
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "print(max_src_len)\n",
        "print(max_tar_len)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n",
            "76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-dN-MsFeYDB"
      },
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od5xlVQjeaAe"
      },
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y33VEgq8egWY"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL0dPGuKe1J1"
      },
      "source": [
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
        "encoder_states = [state_h, state_c]\n",
        "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 바로 은닉 상태와 셀 상태."
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHpRao_BhL_Z"
      },
      "source": [
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다.\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWCBohYGhrni",
        "outputId": "86045f9c-a5a6-4a08-a1b0-335d0c8d5814"
      },
      "source": [
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=30, validation_split=0.2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "750/750 [==============================] - 401s 535ms/step - loss: 0.4427 - val_loss: 0.5299\n",
            "Epoch 2/30\n",
            "750/750 [==============================] - 391s 522ms/step - loss: 0.3778 - val_loss: 0.4744\n",
            "Epoch 3/30\n",
            "750/750 [==============================] - 387s 516ms/step - loss: 0.3387 - val_loss: 0.4392\n",
            "Epoch 4/30\n",
            "750/750 [==============================] - 384s 513ms/step - loss: 0.3121 - val_loss: 0.4152\n",
            "Epoch 5/30\n",
            "750/750 [==============================] - 384s 512ms/step - loss: 0.2921 - val_loss: 0.4000\n",
            "Epoch 6/30\n",
            "750/750 [==============================] - 384s 512ms/step - loss: 0.2764 - val_loss: 0.3879\n",
            "Epoch 7/30\n",
            "750/750 [==============================] - 384s 512ms/step - loss: 0.2639 - val_loss: 0.3796\n",
            "Epoch 8/30\n",
            "750/750 [==============================] - 392s 522ms/step - loss: 0.2532 - val_loss: 0.3758\n",
            "Epoch 9/30\n",
            "750/750 [==============================] - 388s 518ms/step - loss: 0.2440 - val_loss: 0.3675\n",
            "Epoch 10/30\n",
            "750/750 [==============================] - 381s 508ms/step - loss: 0.2358 - val_loss: 0.3640\n",
            "Epoch 11/30\n",
            "750/750 [==============================] - 377s 503ms/step - loss: 0.2285 - val_loss: 0.3610\n",
            "Epoch 12/30\n",
            "750/750 [==============================] - 378s 503ms/step - loss: 0.2219 - val_loss: 0.3604\n",
            "Epoch 13/30\n",
            "750/750 [==============================] - 379s 505ms/step - loss: 0.2160 - val_loss: 0.3575\n",
            "Epoch 14/30\n",
            "750/750 [==============================] - 390s 519ms/step - loss: 0.2103 - val_loss: 0.3583\n",
            "Epoch 15/30\n",
            "750/750 [==============================] - 391s 521ms/step - loss: 0.2051 - val_loss: 0.3552\n",
            "Epoch 16/30\n",
            "750/750 [==============================] - 390s 520ms/step - loss: 0.2004 - val_loss: 0.3588\n",
            "Epoch 17/30\n",
            "750/750 [==============================] - 380s 507ms/step - loss: 0.1959 - val_loss: 0.3591\n",
            "Epoch 18/30\n",
            "750/750 [==============================] - 385s 513ms/step - loss: 0.1916 - val_loss: 0.3574\n",
            "Epoch 19/30\n",
            "750/750 [==============================] - 394s 525ms/step - loss: 0.1877 - val_loss: 0.3614\n",
            "Epoch 20/30\n",
            "750/750 [==============================] - 409s 546ms/step - loss: 0.1838 - val_loss: 0.3609\n",
            "Epoch 21/30\n",
            "750/750 [==============================] - 398s 531ms/step - loss: 0.1803 - val_loss: 0.3629\n",
            "Epoch 22/30\n",
            "750/750 [==============================] - 397s 530ms/step - loss: 0.1770 - val_loss: 0.3639\n",
            "Epoch 23/30\n",
            "750/750 [==============================] - 396s 528ms/step - loss: 0.1737 - val_loss: 0.3673\n",
            "Epoch 24/30\n",
            "750/750 [==============================] - 395s 526ms/step - loss: 0.1707 - val_loss: 0.3688\n",
            "Epoch 25/30\n",
            "750/750 [==============================] - 389s 519ms/step - loss: 0.1679 - val_loss: 0.3704\n",
            "Epoch 26/30\n",
            "750/750 [==============================] - 387s 516ms/step - loss: 0.1650 - val_loss: 0.3732\n",
            "Epoch 27/30\n",
            "750/750 [==============================] - 388s 518ms/step - loss: 0.1624 - val_loss: 0.3752\n",
            "Epoch 28/30\n",
            "750/750 [==============================] - 393s 524ms/step - loss: 0.1598 - val_loss: 0.3768\n",
            "Epoch 29/30\n",
            "750/750 [==============================] - 389s 518ms/step - loss: 0.1576 - val_loss: 0.3789\n",
            "Epoch 30/30\n",
            "750/750 [==============================] - 392s 523ms/step - loss: 0.1551 - val_loss: 0.3817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f11ebc25cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB0d3z7-hsNc"
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb0LKtmmkEK5"
      },
      "source": [
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
        "decoder_states = [state_h, state_c]\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnaflrujot3f"
      },
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6QgqB4couUz"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 문자로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_tar_len):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CltBK6N0s2Tf",
        "outputId": "c7115d4f-1522-410f-9328-c464657e2e49"
      },
      "source": [
        "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
        "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(35 * \"-\")\n",
        "    print('입력 문장:', lines.src[seq_index])\n",
        "    print('정답 문장:', lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "입력 문장: Run!\n",
            "정답 문장:  Cours ! \n",
            "번역기가 번역한 문장:  Courez-vous ! \n",
            "-----------------------------------\n",
            "입력 문장: I left.\n",
            "정답 문장:  Je suis parti. \n",
            "번역기가 번역한 문장:  Je me suis rendue. \n",
            "-----------------------------------\n",
            "입력 문장: Burn it.\n",
            "정답 문장:  Brûlez-la. \n",
            "번역기가 번역한 문장:  Brûle-le. \n",
            "-----------------------------------\n",
            "입력 문장: Drive on.\n",
            "정답 문장:  Continue à rouler ! \n",
            "번역기가 번역한 문장:  Continuez à moi. \n",
            "-----------------------------------\n",
            "입력 문장: Step back.\n",
            "정답 문장:  Recule ! \n",
            "번역기가 번역한 문장:  Reconnez ! \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQoMjTDZs4jc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}