{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "201208_QA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPww/WhuTLREp8vwcd6jMnE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoonYoung-Sohn/practice/blob/master/201208_QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqs5KKcpO_M2"
      },
      "source": [
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import tarfile\n",
        "from nltk import FreqDist\n",
        "from functools import reduce\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL0XhdX5Rewu",
        "outputId": "6fa9ed53-af09-4879-fe79-555070d96cf3"
      },
      "source": [
        "path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/'\n",
        "                'babi_tasks_1-20_v1-2.tar.gz')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
            "11747328/11745123 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKkfqtUzRgZM"
      },
      "source": [
        "with tarfile.open(path) as tar:\n",
        " tar.extractall()\n",
        " tar.close()\n",
        "\n",
        "DATA_DIR = 'tasks_1-20_v1-2/en-10k'\n",
        "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\n",
        "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAtJ1heRRi0l",
        "outputId": "1bb41359-6bda-4d3d-8d03-9ac495600be1"
      },
      "source": [
        "i = 0\n",
        "lines = open(TRAIN_FILE , \"rb\")\n",
        "for line in lines:\n",
        "    line = line.decode(\"utf-8\").strip()\n",
        "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
        "    i = i + 1\n",
        "    print(line)\n",
        "    if i == 20:\n",
        "      break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Mary moved to the bathroom.\n",
            "2 John went to the hallway.\n",
            "3 Where is Mary? \tbathroom\t1\n",
            "4 Daniel went back to the hallway.\n",
            "5 Sandra moved to the garden.\n",
            "6 Where is Daniel? \thallway\t4\n",
            "7 John moved to the office.\n",
            "8 Sandra journeyed to the bathroom.\n",
            "9 Where is Daniel? \thallway\t4\n",
            "10 Mary moved to the hallway.\n",
            "11 Daniel travelled to the office.\n",
            "12 Where is Daniel? \toffice\t11\n",
            "13 John went back to the garden.\n",
            "14 John moved to the bedroom.\n",
            "15 Where is Sandra? \tbathroom\t8\n",
            "1 Sandra travelled to the office.\n",
            "2 Sandra went to the bathroom.\n",
            "3 Where is Sandra? \tbathroom\t2\n",
            "4 Mary went to the bedroom.\n",
            "5 Daniel moved to the hallway.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKMqE0vMRkRY"
      },
      "source": [
        "def read_data(dir):\n",
        "    stories, questions, answers = [], [], [] \n",
        "    story_temp = [] \n",
        "    lines = open(dir, \"rb\")\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.decode(\"utf-8\") \n",
        "        line = line.strip() \n",
        "        idx, text = line.split(\" \", 1) \n",
        "\n",
        "        if int(idx) == 1:\n",
        "            story_temp = []\n",
        "\n",
        "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
        "            question, answer, _ = text.split(\"\\t\") \n",
        "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
        "            questions.append(question)\n",
        "            answers.append(answer)\n",
        "\n",
        "        else: # 현재 읽는 줄이 스토리인 경우\n",
        "            story_temp.append(text) # 임시 저장\n",
        "\n",
        "    lines.close()\n",
        "    return stories, questions, answers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W-6QsqVSdRG"
      },
      "source": [
        "train_data = read_data(TRAIN_FILE)\n",
        "test_data = read_data(TEST_FILE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBq3bAh7Sfqv"
      },
      "source": [
        "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
        "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqTTcIdRSg4O",
        "outputId": "07483800-bd9b-4955-81a1-94aab3288b39"
      },
      "source": [
        "print('훈련용 스토리의 개수 :', len(train_stories))\n",
        "print('훈련용 질문의 개수 :',len(train_questions))\n",
        "print('훈련용 답변의 개수 :',len(train_answers))\n",
        "print('테스트용 스토리의 개수 :',len(test_stories))\n",
        "print('테스트용 질문의 개수 :',len(test_questions))\n",
        "print('테스트용 답변의 개수 :',len(test_answers))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 스토리의 개수 : 10000\n",
            "훈련용 질문의 개수 : 10000\n",
            "훈련용 답변의 개수 : 10000\n",
            "테스트용 스토리의 개수 : 1000\n",
            "테스트용 질문의 개수 : 1000\n",
            "테스트용 답변의 개수 : 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RECianeSi0o",
        "outputId": "23e0e7d9-2c18-4e6b-9dd8-2c166bb86613"
      },
      "source": [
        "train_stories[3576]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John went back to the garden.',\n",
              " 'Mary went to the kitchen.',\n",
              " 'Sandra went back to the bedroom.',\n",
              " 'John travelled to the bedroom.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yNFqPE96SwJA",
        "outputId": "e0ef238a-bcf4-4dc3-d567-920a925f7116"
      },
      "source": [
        "train_questions[3576]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Where is John? '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dv34eNAtS_JT",
        "outputId": "b1507c4f-b443-4abd-c9ac-f5c4ae8d5dd8"
      },
      "source": [
        "train_answers[3576]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bedroom'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RozPC2aQTAT_"
      },
      "source": [
        "def tokenize(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgnx9DSATB1T"
      },
      "source": [
        "def preprocess_data(train_data, test_data):\n",
        "    counter = FreqDist()\n",
        "\n",
        "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    story_len = []\n",
        "    question_len = []\n",
        "\n",
        "    for stories, questions, answers in [train_data, test_data]:\n",
        "        for story in stories:\n",
        "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
        "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
        "            for word in stories: # 단어 집합에 단어 추가\n",
        "                counter[word] += 1\n",
        "        for question in questions:\n",
        "            question = tokenize(question)\n",
        "            question_len.append(len(question))\n",
        "            for word in question:\n",
        "                counter[word] += 1\n",
        "        for answer in answers:\n",
        "            answer = tokenize(answer)\n",
        "            for word in answer:\n",
        "                counter[word] += 1\n",
        "\n",
        "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
        "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
        "\n",
        "    story_max_len = np.max(story_len)\n",
        "    question_max_len = np.max(question_len)\n",
        "\n",
        "    return word2idx, idx2word, story_max_len, question_max_len"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66TA8fcoTUfp",
        "outputId": "1df813af-f73a-4b61-9b1b-f226da20f1c1"
      },
      "source": [
        "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKnCyW2NTV6V",
        "outputId": "f96ddadf-5209-4ebd-d5fa-7d6878174615"
      },
      "source": [
        "print(word2idx)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'to': 1, 'the': 2, '.': 3, 'went': 4, 'Sandra': 5, 'John': 6, 'Daniel': 7, 'Mary': 8, 'travelled': 9, 'journeyed': 10, 'back': 11, 'bathroom': 12, 'garden': 13, 'hallway': 14, 'moved': 15, 'office': 16, 'kitchen': 17, 'bedroom': 18, 'Where': 19, 'is': 20, '?': 21}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NtQmhjnTXF2"
      },
      "source": [
        "vocab_size = len(word2idx) + 1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsTYVbDGTYW_",
        "outputId": "640a1159-893f-4e78-88dd-2d09e8bff200"
      },
      "source": [
        "print('스토리의 최대 길이 :',story_max_len)\n",
        "print('질문의 최대 길이 :',question_max_len)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "스토리의 최대 길이 : 68\n",
            "질문의 최대 길이 : 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3p4RwtsTZjM"
      },
      "source": [
        "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
        "    Xs, Xq, Y = [], [], []\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    stories, questions, answers = data\n",
        "    for story, question, answer in zip(stories, questions, answers):\n",
        "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
        "        xq = [word2idx[w] for w in tokenize(question)]\n",
        "        Xs.append(xs)\n",
        "        Xq.append(xq)\n",
        "        Y.append(word2idx[answer])\n",
        "\n",
        "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
        "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
        "           to_categorical(Y, num_classes=len(word2idx) + 1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL5C6csOTckk",
        "outputId": "b9850e9a-b56d-4d60-8037-810d24a62241"
      },
      "source": [
        "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
        "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMvYmXvZTfOE",
        "outputId": "f46731f9-4cc2-4ebb-8332-f1564106e62f"
      },
      "source": [
        "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 68) (10000, 4) (10000, 22) (1000, 68) (1000, 4) (1000, 22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z64T-IRTg22"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUn5xtlpTjFb"
      },
      "source": [
        "train_epochs = 120\n",
        "batch_size = 32\n",
        "embed_size = 50\n",
        "lstm_size = 64\n",
        "dropout_rate = 0.30"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS3Dq_c0TmMj",
        "outputId": "91e0363d-e139-4c1e-f122-7ebc551cc7cf"
      },
      "source": [
        "input_sequence = Input((story_max_len,))\n",
        "question = Input((question_max_len,))\n",
        "\n",
        "print('Stories :', input_sequence)\n",
        "print('Question:', question)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stories : Tensor(\"input_1:0\", shape=(None, 68), dtype=float32)\n",
            "Question: Tensor(\"input_2:0\", shape=(None, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irbrMxXATnyy"
      },
      "source": [
        "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=embed_size))\n",
        "input_encoder_m.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, story_max_len, embedding_dim) \n",
        "\n",
        "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
        "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=question_max_len))\n",
        "input_encoder_c.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, story_max_len, question_max_len) "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C2hhqJmUL6v"
      },
      "source": [
        "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=embed_size,\n",
        "                               input_length=question_max_len))\n",
        "question_encoder.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, question_max_len, embedding_dim) "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha63OEX1UOBY",
        "outputId": "00645912-2993-4d4f-ad29-5db0abf4efbe"
      },
      "source": [
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "print('Input encoded m', input_encoded_m)\n",
        "print('Input encoded c', input_encoded_c)\n",
        "print('Question encoded', question_encoded)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input encoded m Tensor(\"sequential/dropout/cond/Identity:0\", shape=(None, 68, 50), dtype=float32)\n",
            "Input encoded c Tensor(\"sequential_1/dropout_1/cond/Identity:0\", shape=(None, 68, 4), dtype=float32)\n",
            "Question encoded Tensor(\"sequential_2/dropout_2/cond/Identity:0\", shape=(None, 4, 50), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01kt0PrPUPkf",
        "outputId": "ec8c7b0d-19c2-419e-ff22-01306572a808"
      },
      "source": [
        "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
        "match = Activation('softmax')(match)\n",
        "print('Match shape', match)\n",
        "# 결과 : (samples, story_maxlen, question_max_len)\n",
        "\n",
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_max_len, question_max_len)\n",
        "response = Permute((2, 1))(response)  # (samples, question_max_len, story_max_len)\n",
        "print('Response shape', response)\n",
        "\n",
        "# concatenate the response vector with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])\n",
        "print('Answer shape', answer)\n",
        "\n",
        "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
        "answer = Dropout(dropout_rate)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
        "answer = Activation('softmax')(answer)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Match shape Tensor(\"activation/truediv:0\", shape=(None, 68, 4), dtype=float32)\n",
            "Response shape Tensor(\"permute/transpose:0\", shape=(None, 4, 68), dtype=float32)\n",
            "Answer shape Tensor(\"concatenate/concat:0\", shape=(None, 4, 118), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dyW2SnNUX5t",
        "outputId": "3701d358-d4ba-4246-9d06-3b405d8b899d"
      },
      "source": [
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "history = model.fit([Xstrain, Xqtrain],\n",
        "         Ytrain, batch_size, train_epochs,\n",
        "         validation_data=([Xstest, Xqtest], Ytest))\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 68)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, None, 50)     1100        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 4, 50)        1100        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 68, 4)        0           sequential[0][0]                 \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 68, 4)        0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, None, 4)      88          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 68, 4)        0           activation[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 4, 68)        0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4, 118)       0           permute[0][0]                    \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           46848       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64)           0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 22)           1430        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 22)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 50,566\n",
            "Trainable params: 50,566\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.8923 - acc: 0.1635 - val_loss: 1.7814 - val_acc: 0.2680\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.7107 - acc: 0.2641 - val_loss: 1.6271 - val_acc: 0.3440\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.5873 - acc: 0.3731 - val_loss: 1.4877 - val_acc: 0.4190\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.5059 - acc: 0.4146 - val_loss: 1.4390 - val_acc: 0.4450\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.4503 - acc: 0.4438 - val_loss: 1.3739 - val_acc: 0.4590\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.4060 - acc: 0.4587 - val_loss: 1.3757 - val_acc: 0.4460\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3618 - acc: 0.4676 - val_loss: 1.3200 - val_acc: 0.4820\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3451 - acc: 0.4867 - val_loss: 1.3147 - val_acc: 0.4830\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3201 - acc: 0.4882 - val_loss: 1.2940 - val_acc: 0.5120\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3020 - acc: 0.4971 - val_loss: 1.2803 - val_acc: 0.5180\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2789 - acc: 0.5015 - val_loss: 1.2437 - val_acc: 0.5120\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2480 - acc: 0.5116 - val_loss: 1.2263 - val_acc: 0.5170\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2254 - acc: 0.5197 - val_loss: 1.2187 - val_acc: 0.5140\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1930 - acc: 0.5165 - val_loss: 1.1673 - val_acc: 0.5270\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1756 - acc: 0.5214 - val_loss: 1.1893 - val_acc: 0.5110\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1628 - acc: 0.5178 - val_loss: 1.1547 - val_acc: 0.5380\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1607 - acc: 0.5208 - val_loss: 1.1448 - val_acc: 0.5220\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1522 - acc: 0.5235 - val_loss: 1.1618 - val_acc: 0.5230\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1338 - acc: 0.5288 - val_loss: 1.1420 - val_acc: 0.5220\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1393 - acc: 0.5251 - val_loss: 1.1452 - val_acc: 0.5210\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1202 - acc: 0.5277 - val_loss: 1.1286 - val_acc: 0.5240\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1186 - acc: 0.5287 - val_loss: 1.1422 - val_acc: 0.5400\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1063 - acc: 0.5330 - val_loss: 1.1537 - val_acc: 0.5200\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1089 - acc: 0.5330 - val_loss: 1.1513 - val_acc: 0.5260\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0975 - acc: 0.5371 - val_loss: 1.1418 - val_acc: 0.5370\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0948 - acc: 0.5409 - val_loss: 1.1288 - val_acc: 0.5230\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0852 - acc: 0.5338 - val_loss: 1.1448 - val_acc: 0.5260\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0845 - acc: 0.5478 - val_loss: 1.1474 - val_acc: 0.5180\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0846 - acc: 0.5364 - val_loss: 1.1332 - val_acc: 0.5120\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0769 - acc: 0.5461 - val_loss: 1.1498 - val_acc: 0.5220\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0630 - acc: 0.5577 - val_loss: 1.1593 - val_acc: 0.5100\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0569 - acc: 0.5526 - val_loss: 1.1339 - val_acc: 0.5170\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0547 - acc: 0.5537 - val_loss: 1.1454 - val_acc: 0.5190\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0474 - acc: 0.5576 - val_loss: 1.1315 - val_acc: 0.5300\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0302 - acc: 0.5652 - val_loss: 1.1353 - val_acc: 0.5260\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0168 - acc: 0.5719 - val_loss: 1.1172 - val_acc: 0.5350\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.9815 - acc: 0.5914 - val_loss: 1.0565 - val_acc: 0.5640\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8814 - acc: 0.6482 - val_loss: 0.8558 - val_acc: 0.6920\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.7181 - acc: 0.7309 - val_loss: 0.7309 - val_acc: 0.7300\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6273 - acc: 0.7678 - val_loss: 0.6613 - val_acc: 0.7550\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5805 - acc: 0.7870 - val_loss: 0.6154 - val_acc: 0.7630\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5291 - acc: 0.8021 - val_loss: 0.5540 - val_acc: 0.7850\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4738 - acc: 0.8197 - val_loss: 0.4954 - val_acc: 0.7950\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4280 - acc: 0.8412 - val_loss: 0.4380 - val_acc: 0.8180\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3991 - acc: 0.8498 - val_loss: 0.4051 - val_acc: 0.8540\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3611 - acc: 0.8653 - val_loss: 0.3919 - val_acc: 0.8470\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3339 - acc: 0.8757 - val_loss: 0.3687 - val_acc: 0.8610\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3157 - acc: 0.8832 - val_loss: 0.3615 - val_acc: 0.8670\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3052 - acc: 0.8856 - val_loss: 0.3600 - val_acc: 0.8700\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2826 - acc: 0.8936 - val_loss: 0.3522 - val_acc: 0.8680\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2797 - acc: 0.8990 - val_loss: 0.3402 - val_acc: 0.8730\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2653 - acc: 0.8989 - val_loss: 0.3359 - val_acc: 0.8830\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2501 - acc: 0.9059 - val_loss: 0.3337 - val_acc: 0.8830\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2320 - acc: 0.9146 - val_loss: 0.2935 - val_acc: 0.8990\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2244 - acc: 0.9193 - val_loss: 0.3034 - val_acc: 0.8890\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1955 - acc: 0.9290 - val_loss: 0.2635 - val_acc: 0.9090\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1900 - acc: 0.9326 - val_loss: 0.2597 - val_acc: 0.9040\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1759 - acc: 0.9393 - val_loss: 0.2260 - val_acc: 0.9150\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1627 - acc: 0.9432 - val_loss: 0.2528 - val_acc: 0.9160\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1517 - acc: 0.9479 - val_loss: 0.2240 - val_acc: 0.9270\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1357 - acc: 0.9537 - val_loss: 0.2427 - val_acc: 0.9180\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1245 - acc: 0.9569 - val_loss: 0.2211 - val_acc: 0.9340\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1241 - acc: 0.9563 - val_loss: 0.2121 - val_acc: 0.9440\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1231 - acc: 0.9584 - val_loss: 0.2003 - val_acc: 0.9380\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1039 - acc: 0.9645 - val_loss: 0.1826 - val_acc: 0.9510\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1039 - acc: 0.9617 - val_loss: 0.1830 - val_acc: 0.9470\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0989 - acc: 0.9660 - val_loss: 0.1756 - val_acc: 0.9530\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0930 - acc: 0.9700 - val_loss: 0.1969 - val_acc: 0.9380\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0978 - acc: 0.9670 - val_loss: 0.1684 - val_acc: 0.9470\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0935 - acc: 0.9675 - val_loss: 0.1957 - val_acc: 0.9500\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0884 - acc: 0.9718 - val_loss: 0.1763 - val_acc: 0.9480\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0918 - acc: 0.9687 - val_loss: 0.1844 - val_acc: 0.9480\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0840 - acc: 0.9719 - val_loss: 0.1725 - val_acc: 0.9410\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0797 - acc: 0.9723 - val_loss: 0.1468 - val_acc: 0.9610\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0731 - acc: 0.9742 - val_loss: 0.1750 - val_acc: 0.9500\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0695 - acc: 0.9753 - val_loss: 0.1958 - val_acc: 0.9500\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0683 - acc: 0.9760 - val_loss: 0.1686 - val_acc: 0.9600\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0660 - acc: 0.9785 - val_loss: 0.1914 - val_acc: 0.9540\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0655 - acc: 0.9799 - val_loss: 0.1633 - val_acc: 0.9550\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0595 - acc: 0.9796 - val_loss: 0.1844 - val_acc: 0.9450\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0597 - acc: 0.9799 - val_loss: 0.1724 - val_acc: 0.9580\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0576 - acc: 0.9817 - val_loss: 0.1769 - val_acc: 0.9600\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0551 - acc: 0.9819 - val_loss: 0.2082 - val_acc: 0.9490\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0613 - acc: 0.9791 - val_loss: 0.1810 - val_acc: 0.9570\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0515 - acc: 0.9818 - val_loss: 0.1917 - val_acc: 0.9550\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0557 - acc: 0.9821 - val_loss: 0.1770 - val_acc: 0.9550\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0545 - acc: 0.9821 - val_loss: 0.1826 - val_acc: 0.9500\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0519 - acc: 0.9825 - val_loss: 0.1818 - val_acc: 0.9530\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0513 - acc: 0.9831 - val_loss: 0.1761 - val_acc: 0.9540\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0494 - acc: 0.9824 - val_loss: 0.1544 - val_acc: 0.9630\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0479 - acc: 0.9849 - val_loss: 0.1858 - val_acc: 0.9550\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0498 - acc: 0.9836 - val_loss: 0.1558 - val_acc: 0.9600\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0552 - acc: 0.9828 - val_loss: 0.1564 - val_acc: 0.9660\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0560 - acc: 0.9823 - val_loss: 0.1538 - val_acc: 0.9540\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0424 - acc: 0.9874 - val_loss: 0.1642 - val_acc: 0.9610\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0483 - acc: 0.9858 - val_loss: 0.1700 - val_acc: 0.9560\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0402 - acc: 0.9874 - val_loss: 0.1417 - val_acc: 0.9580\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0458 - acc: 0.9861 - val_loss: 0.1722 - val_acc: 0.9540\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0404 - acc: 0.9879 - val_loss: 0.1669 - val_acc: 0.9620\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0399 - acc: 0.9869 - val_loss: 0.1535 - val_acc: 0.9640\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0420 - acc: 0.9865 - val_loss: 0.1501 - val_acc: 0.9650\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0403 - acc: 0.9888 - val_loss: 0.1470 - val_acc: 0.9630\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0430 - acc: 0.9857 - val_loss: 0.1540 - val_acc: 0.9600\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0427 - acc: 0.9872 - val_loss: 0.1484 - val_acc: 0.9660\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0377 - acc: 0.9885 - val_loss: 0.1365 - val_acc: 0.9620\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0423 - acc: 0.9873 - val_loss: 0.1414 - val_acc: 0.9670\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0348 - acc: 0.9894 - val_loss: 0.1795 - val_acc: 0.9600\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0413 - acc: 0.9884 - val_loss: 0.1425 - val_acc: 0.9630\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0376 - acc: 0.9878 - val_loss: 0.1754 - val_acc: 0.9610\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0393 - acc: 0.9892 - val_loss: 0.1506 - val_acc: 0.9640\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0345 - acc: 0.9886 - val_loss: 0.1503 - val_acc: 0.9680\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0332 - acc: 0.9903 - val_loss: 0.1339 - val_acc: 0.9720\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0353 - acc: 0.9901 - val_loss: 0.1445 - val_acc: 0.9660\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0372 - acc: 0.9880 - val_loss: 0.1446 - val_acc: 0.9670\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0330 - acc: 0.9888 - val_loss: 0.1427 - val_acc: 0.9630\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0310 - acc: 0.9907 - val_loss: 0.1371 - val_acc: 0.9730\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0430 - acc: 0.9875 - val_loss: 0.1511 - val_acc: 0.9600\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0353 - acc: 0.9892 - val_loss: 0.1468 - val_acc: 0.9660\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0355 - acc: 0.9887 - val_loss: 0.1582 - val_acc: 0.9620\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0381 - acc: 0.9894 - val_loss: 0.1247 - val_acc: 0.9680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "664z_5LIUg8n",
        "outputId": "cd849302-8882-4c65-fc64-74e45835d2e2"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1247 - acc: 0.9680\n",
            "\n",
            " 테스트 정확도: 0.9680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "18X0hFYYUhZ2",
        "outputId": "92ab56ca-9f5a-4849-82ae-76f082dd8881"
      },
      "source": [
        "plt.subplot(211)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "ytest = np.argmax(Ytest, axis=1)\n",
        "Ytest_ = model.predict([Xstest, Xqtest])\n",
        "ytest_ = np.argmax(Ytest_, axis=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}